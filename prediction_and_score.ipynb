{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "prediction_and_score.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9978b130"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "9978b130",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SznK61_K5HqY"
      },
      "source": [
        "test_df= pd.read_csv(\"test2.csv\") #reading a txt file with single datapoint"
      ],
      "id": "SznK61_K5HqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXsjVZ7A71j0"
      },
      "source": [
        "# Predict_outcome_function:"
      ],
      "id": "qXsjVZ7A71j0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0U7sIeW0XNF"
      },
      "source": [
        "def final1(df):\n",
        "  import time\n",
        "  start= time.time()\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "    \n",
        "  #if 'pandas.core.series.Series' is given instead of dataframe:\n",
        "  if isinstance(df, pd.core.series.Series):\n",
        "    values= list((df.to_frame()).iloc[:, 0]) #get_values\n",
        "    cols= list(df.to_frame().index) #get index\n",
        "    df= pd.DataFrame([values], columns = cols)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  test_id= (df.iloc[0]['ID']).astype(int)\n",
        "  test_df= df.drop(['ID'], axis=1)\n",
        "\n",
        "  #data cleaning:\n",
        "  # load pickle with all removable_features\n",
        "  import pickle\n",
        "  with open('pickle/const_feat.pkl', 'rb') as o:\n",
        "      const_feat = pickle.load(o)\n",
        "  with open('pickle/quasi_const_feat.pkl', 'rb') as o:\n",
        "      quasi_const_feat = pickle.load(o)\n",
        "  with open('pickle/correlated_columns.pkl', 'rb') as o:\n",
        "      correlated_columns = pickle.load(o)\n",
        "  with open('pickle/sparse_columns.pkl', 'rb') as o:\n",
        "      sparse_columns = pickle.load(o)\n",
        "\n",
        "  remove_cols= const_feat+ quasi_const_feat+ correlated_columns+ sparse_columns\n",
        "\n",
        "  def drop_fetures(df):\n",
        "    df.drop(set(remove_cols), axis=1, inplace= True)\n",
        "\n",
        "  drop_fetures(test_df)\n",
        "\n",
        "  #adding new features:\n",
        "  def count_of_zeros(df):\n",
        "    df.insert((df.shape[1]), 'count_zeros', (df == 0).astype(int).sum(axis=1))\n",
        "\n",
        "  def count_of_non_zeros(df):\n",
        "    df.insert((df.shape[1]), 'count_non_zeros', (df != 0).astype(int).sum(axis=1))\n",
        "\n",
        "  def age_below_23(df):\n",
        "    below_23= []\n",
        "    for i in (df['var15']):\n",
        "      if i < 23:\n",
        "        below_23.append(1)\n",
        "      else:\n",
        "        below_23.append(0)\n",
        "\n",
        "    df['below_23']= below_23\n",
        "\n",
        "  def age_above_80(df):\n",
        "    above_80= []\n",
        "    for i in (df['var15']):\n",
        "      if i > 80:\n",
        "        above_80.append(1)\n",
        "      else:\n",
        "        above_80.append(0)\n",
        "\n",
        "    df['above_80']= above_80\n",
        "\n",
        "  def saldo_var30_0_3(df):\n",
        "    saldo_var30_0_3= []\n",
        "    for i in (df['saldo_var30']):\n",
        "      if ((i == 0)or(i ==3)):\n",
        "        saldo_var30_0_3.append(1)\n",
        "      else:\n",
        "        saldo_var30_0_3.append(0)\n",
        "\n",
        "    df['saldo_var30_0_3']= saldo_var30_0_3\n",
        "\n",
        "  def value_var38(df):\n",
        "    value_var38= []\n",
        "    for i in (df['var38']):\n",
        "      if (i == 117310.979016494):\n",
        "        value_var38.append(1)\n",
        "      else:\n",
        "        value_var38.append(0)\n",
        "\n",
        "    df['value_var38']= value_var38\n",
        "\n",
        "  def value_saldo_medio_var5_ult3(df):\n",
        "    value_saldo_medio_var5_ult3= []\n",
        "    for i in (df['saldo_medio_var5_ult3']):\n",
        "      if (i == 0.0):\n",
        "        value_saldo_medio_var5_ult3.append(1)\n",
        "      else:\n",
        "        value_saldo_medio_var5_ult3.append(0)\n",
        "\n",
        "    df['value_saldo_medio_var5_ult3']= value_saldo_medio_var5_ult3\n",
        "\n",
        "  count_of_zeros(test_df)\n",
        "\n",
        "  count_of_non_zeros(test_df)\n",
        "\n",
        "  age_below_23(test_df)\n",
        "\n",
        "  age_above_80(test_df)\n",
        "\n",
        "  saldo_var30_0_3(test_df)\n",
        "\n",
        "  value_var38(test_df)\n",
        "\n",
        "  value_saldo_medio_var5_ult3(test_df)\n",
        "\n",
        "  #load models:\n",
        "  import tensorflow as tf\n",
        "\n",
        "  with open('pickle/clf_rf.pkl', 'rb') as o: #random_forest\n",
        "      clf_rf = pickle.load(o)\n",
        "  with open('pickle/clf_xgbrf.pkl', 'rb') as o: #xgbrfclassifier\n",
        "      clf_xgbrf = pickle.load(o)\n",
        "  with open('pickle/clf_xgb.pkl', 'rb') as o:#xgboost\n",
        "      clf_xgb = pickle.load(o)\n",
        "  with open('pickle/clf_lgbm.pkl', 'rb') as o:#lgbmclassifier\n",
        "      clf_lgbm = pickle.load(o)\n",
        "  with open('pickle/clf_adb.pkl', 'rb') as o:#adbclassifier\n",
        "      clf_adb = pickle.load(o)\n",
        "  model = tf.keras.models.load_model('pickle/dl_model')#neuaral network model\n",
        "\n",
        "  with open('pickle/scaler.pkl', 'rb') as o:\n",
        "      scaler = pickle.load(o)\n",
        "\n",
        "  #preparing data for deep learning:\n",
        "  print(test_df)\n",
        "  test_df_dl= scaler.transform(test_df)\n",
        "  X_test_dl = test_df_dl.reshape(test_df.shape[0], test_df.shape[1], 1)\n",
        "\n",
        "  # get prediction_probablity:\n",
        "  y_test_pred_rf = clf_rf.predict_proba(test_df)[:,1]\n",
        "  y_test_pred_xgbrf = clf_xgbrf.predict_proba(test_df)[:,1]\n",
        "  y_test_pred_xgb = clf_xgb.predict_proba(test_df)[:,1]\n",
        "  y_test_pred_lgbm = clf_lgbm.predict_proba(test_df)[:,1]\n",
        "  y_test_pred_adb = clf_adb.predict_proba(test_df) [:,1]\n",
        "\n",
        "  y_test_pred= model.predict(X_test_dl) #dl model\n",
        "  y_test_pred_dl= []\n",
        "  for i in range(y_test_pred.shape[0]):\n",
        "    y_test_pred_dl.append(y_test_pred[i][0])\n",
        "\n",
        "  y_test_pred= (y_test_pred_rf+ y_test_pred_xgbrf+ y_test_pred_xgb+ y_test_pred_lgbm+ y_test_pred_adb+ y_test_pred_dl )/6\n",
        "\n",
        "  #make prediction\n",
        "  prediction=[]\n",
        "  for i in y_test_pred:\n",
        "    if i > 0.5:\n",
        "      prediction.append(\"UNSATISFIED\")\n",
        "    else:\n",
        "      prediction.append(\"SATISFIED\")\n",
        "      \n",
        "  if len(prediction)==1:\n",
        "    prediction= prediction[0]\n",
        "  else:\n",
        "    pass\n",
        "  prediction=\"prediction: {}\".format(prediction)\n",
        "\n",
        "  end= time.time()\n",
        "  execution_time= end-start\n",
        "  execution_time= \"time of execution :{} seconds\".format(end-start)\n",
        "  return prediction, execution_time"
      ],
      "id": "j0U7sIeW0XNF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8be384aa",
        "scrolled": false
      },
      "source": [
        "result= final1(test_df)"
      ],
      "id": "8be384aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82319bd7",
        "scrolled": true,
        "outputId": "afb1a2d3-0f59-4c61-a79f-89de9f2fb897"
      },
      "source": [
        "result"
      ],
      "id": "82319bd7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('prediction: SATISFIED', 'time of execution :0.5045850276947021 seconds')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn-ZwHj93uaz"
      },
      "source": [
        "# performance_metric_function:"
      ],
      "id": "Sn-ZwHj93uaz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MHCXq0L5w_O"
      },
      "source": [
        "train_df= pd.read_csv(\"train.csv\")\n",
        "y_true= train_df['TARGET']\n",
        "train_df=train_df.drop('TARGET', axis=1)"
      ],
      "id": "3MHCXq0L5w_O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9I4bqq-3-Xn"
      },
      "source": [
        "def final2(df,y_true):\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  from sklearn.metrics import roc_curve, auc\n",
        "  \n",
        "  y_true=y_true\n",
        "\n",
        "  #if 'pandas.core.series.Series' is given instead of dataframe:\n",
        "  if isinstance(df, pd.core.series.Series):\n",
        "    values= list((df.to_frame()).iloc[:, 0]) #get_values\n",
        "    cols= list(df.to_frame().index) #get index\n",
        "    df= pd.DataFrame([values], columns = cols)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  if 'TARGET' in df.columns:\n",
        "    y_true= df['TARGET']\n",
        "    df=df.drop(['TARGET'], axis=1)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  if 'ID' in df.columns:\n",
        "    test_id= df['ID'] \n",
        "    df= df.drop(['ID'], axis=1)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  #data cleaning:\n",
        "  # load pickle with all removable_features\n",
        "  import pickle\n",
        "  with open('pickle/const_feat.pkl', 'rb') as o:\n",
        "      const_feat = pickle.load(o)\n",
        "  with open('pickle/quasi_const_feat.pkl', 'rb') as o:\n",
        "      quasi_const_feat = pickle.load(o)\n",
        "  with open('pickle/correlated_columns.pkl', 'rb') as o:\n",
        "      correlated_columns = pickle.load(o)\n",
        "  with open('pickle/sparse_columns.pkl', 'rb') as o:\n",
        "      sparse_columns = pickle.load(o)\n",
        "\n",
        "  remove_cols= const_feat+ quasi_const_feat+ correlated_columns+ sparse_columns\n",
        "\n",
        "  def drop_features(df):\n",
        "    df.drop(set(remove_cols), axis=1, inplace= True)\n",
        "\n",
        "  drop_features(df)\n",
        "\n",
        "  #adding new features:\n",
        "  def count_of_zeros(df):\n",
        "    df.insert((df.shape[1]), 'count_zeros', (df == 0).astype(int).sum(axis=1))\n",
        "\n",
        "  def count_of_non_zeros(df):\n",
        "    df.insert((df.shape[1]), 'count_non_zeros', (df != 0).astype(int).sum(axis=1))\n",
        "\n",
        "  def age_below_23(df):\n",
        "    below_23= []\n",
        "    for i in (df['var15']):\n",
        "      if i < 23:\n",
        "        below_23.append(1)\n",
        "      else:\n",
        "        below_23.append(0)\n",
        "\n",
        "    df['below_23']= below_23\n",
        "\n",
        "  def age_above_80(df):\n",
        "    above_80= []\n",
        "    for i in (df['var15']):\n",
        "      if i > 80:\n",
        "        above_80.append(1)\n",
        "      else:\n",
        "        above_80.append(0)\n",
        "\n",
        "    df['above_80']= above_80\n",
        "\n",
        "  def saldo_var30_0_3(df):\n",
        "    saldo_var30_0_3= []\n",
        "    for i in (df['saldo_var30']):\n",
        "      if ((i == 0)or(i ==3)):\n",
        "        saldo_var30_0_3.append(1)\n",
        "      else:\n",
        "        saldo_var30_0_3.append(0)\n",
        "\n",
        "    df['saldo_var30_0_3']= saldo_var30_0_3\n",
        "\n",
        "  def value_var38(df):\n",
        "    value_var38= []\n",
        "    for i in (df['var38']):\n",
        "      if (i == 117310.979016494):\n",
        "        value_var38.append(1)\n",
        "      else:\n",
        "        value_var38.append(0)\n",
        "\n",
        "    df['value_var38']= value_var38\n",
        "\n",
        "  def value_saldo_medio_var5_ult3(df):\n",
        "    value_saldo_medio_var5_ult3= []\n",
        "    for i in (df['saldo_medio_var5_ult3']):\n",
        "      if (i == 0.0):\n",
        "        value_saldo_medio_var5_ult3.append(1)\n",
        "      else:\n",
        "        value_saldo_medio_var5_ult3.append(0)\n",
        "\n",
        "    df['value_saldo_medio_var5_ult3']= value_saldo_medio_var5_ult3\n",
        "\n",
        "  count_of_zeros(df)\n",
        "\n",
        "  count_of_non_zeros(df)\n",
        "\n",
        "  age_below_23(df)\n",
        "\n",
        "  age_above_80(df)\n",
        "\n",
        "  saldo_var30_0_3(df)\n",
        "\n",
        "  value_var38(df)\n",
        "\n",
        "  value_saldo_medio_var5_ult3(df)\n",
        "\n",
        "  #load models:\n",
        "  import tensorflow as tf\n",
        "\n",
        "  with open('pickle/clf_rf.pkl', 'rb') as o: #random_forest\n",
        "      clf_rf = pickle.load(o)\n",
        "  with open('pickle/clf_xgbrf.pkl', 'rb') as o: #xgbrfclassifier\n",
        "      clf_xgbrf = pickle.load(o)\n",
        "  with open('pickle/clf_xgb.pkl', 'rb') as o:#xgboost\n",
        "      clf_xgb = pickle.load(o)\n",
        "  with open('pickle/clf_lgbm.pkl', 'rb') as o:#lgbmclassifier\n",
        "      clf_lgbm = pickle.load(o)\n",
        "  with open('pickle/clf_adb.pkl', 'rb') as o:#adbclassifier\n",
        "      clf_adb = pickle.load(o)\n",
        "  model = tf.keras.models.load_model('pickle/dl_model')#neuaral network model\n",
        "\n",
        "  with open('pickle/scaler.pkl', 'rb') as o:\n",
        "      scaler = pickle.load(o)\n",
        "\n",
        "  #preparing data for deep learning:\n",
        "  df_dl= scaler.transform(df)\n",
        "  X_dl = df_dl.reshape(df.shape[0], df.shape[1], 1)\n",
        "\n",
        "  # get prediction_probablity:\n",
        "  y_test_pred_rf = clf_rf.predict_proba(df)[:,1]\n",
        "  y_test_pred_xgbrf = clf_xgbrf.predict_proba(df)[:,1]\n",
        "  y_test_pred_xgb = clf_xgb.predict_proba(df)[:,1]\n",
        "  y_test_pred_lgbm = clf_lgbm.predict_proba(df)[:,1]\n",
        "  y_test_pred_adb = clf_adb.predict_proba(df) [:,1]\n",
        "\n",
        "  y_test_pred= model.predict(X_dl) #dl model\n",
        "  y_test_pred_dl= []\n",
        "  for i in range(y_test_pred.shape[0]):\n",
        "    y_test_pred_dl.append(y_test_pred[i][0])\n",
        "\n",
        "  y_true= y_true\n",
        "  y_test_pred= (y_test_pred_rf+ y_test_pred_xgbrf+ y_test_pred_xgb+ y_test_pred_lgbm+ y_test_pred_adb+ y_test_pred_dl )/6\n",
        "\n",
        "  test_fpr, test_tpr, tr_thresholds = roc_curve(y_true, y_test_pred)\n",
        "\n",
        "  score= auc(test_fpr, test_tpr)\n",
        "  return score"
      ],
      "id": "P9I4bqq-3-Xn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptTMx79R6LaP",
        "outputId": "486a8495-8455-455b-be5a-be6c8e8032ec"
      },
      "source": [
        "final2(train_df,y_true)"
      ],
      "id": "ptTMx79R6LaP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.915757344901625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04e27274"
      },
      "source": [
        ""
      ],
      "id": "04e27274",
      "execution_count": null,
      "outputs": []
    }
  ]
}